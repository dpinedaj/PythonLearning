{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# countByWindow transformation Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Transformation        | Meaning           |\n",
    "| -------------:|:-------------|\n",
    "| **window**(windowLength, slideInterval)      | Return a new DStream which is computed based on windowed batches of the source DStream. |\n",
    "| **countByWindow**(windowLength, slideInterval)     | Return a sliding window count of elements in the stream.     |\n",
    "| **reduceByWindow**(func, windowLength, slideInterval) | Return a new single-element stream, created by aggregating elements in the stream over a sliding interval using func. The function should be associative and commutative so that it can be computed correctly in parallel.     |\n",
    "| **reduceByKeyAndWindow**(func, windowLength, slideInterval, [numTasks])     | When called on a DStream of (K, V) pairs, returns a new DStream of (K, V) pairs where the values for each key are aggregated using the given reduce function func over batches in a sliding window. Note: By default, this uses Spark's default number of parallel tasks (2 for local mode, and in cluster mode the number is determined by the config property spark.default.parallelism) to do the grouping. You can pass an optional numTasks argument to set a different number of tasks. |\n",
    "| **reduceByKeyAndWindow**(func, invFunc, windowLength, slideInterval, [numTasks])      | A more efficient version of the above reduceByKeyAndWindow() where the reduce value of each window is calculated incrementally using the reduce values of the previous window. This is done by reducing the new data that enters the sliding window, and “inverse reducing” the old data that leaves the window. An example would be that of “adding” and “subtracting” counts of keys as the window slides. However, it is applicable only to “invertible reduce functions”, that is, those reduce functions which have a corresponding “inverse reduce” function (taken as parameter invFunc). Like in reduceByKeyAndWindow, the number of reduce tasks is configurable through an optional argument. Note that checkpointing must be enabled for using this operation.      |\n",
    "| **countByValueAndWindow**(windowLength, slideInterval, [numTasks]) | When called on a DStream of (K, V) pairs, returns a new DStream of (K, Long) pairs where the value of each key is its frequency within a sliding window. Like in reduceByKeyAndWindow, the number of reduce tasks is configurable through an optional argument.      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain countByWindow transformation in depth and what is the usage of countByWindow function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "# TODO: your path will likely not have 'matthew' in it. Change it to reflect your path.\n",
    "findspark.init('/home/matthew/spark-2.1.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "import sys\n",
    "import random\n",
    "from apache_log_parser import ApacheAccessLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[4]\").setAppName(\"log processor\").set(\"spark.executor.memory\", \"2g\"))\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "ssc = StreamingContext(sc, 2)\n",
    "ssc.checkpoint(\"checkpoint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DStream from text file\n",
    "# Note: the spark streaming checks for any updates to this directory.\n",
    "# So first, start this program, and then copy the log file logs/access_log.log to 'directory' location\n",
    "log_data = ssc.textFileStream('logs')\n",
    "access_log_dstream = log_data.map(ApacheAccessLog.parse_from_log_line).filter(lambda parsed_line: parsed_line is not None)\n",
    "ip_dstream = access_log_dstream.map(lambda parsed_line: (parsed_line.ip, 1)) \n",
    "ip_count = ip_dstream.reduceByKey(lambda x,y: x+y)\n",
    "ip_count.pprint(num = 30)\n",
    "ip_bytes_dstream = access_log_dstream.map(lambda parsed_line: (parsed_line.ip, parsed_line.content_size))\n",
    "ip_bytes_sum_dstream = ip_bytes_dstream.reduceByKey(lambda x,y: x+y)\n",
    "ip_bytes_request_count_dstream = ip_count.join(ip_bytes_sum_dstream)\n",
    "ip_bytes_request_count_dstream.pprint(num = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### TODO: Windowed count operation using countByWindow() ###########\n",
    "\n",
    "request_count = access_log_dstream.countByWindow(windowDuration = 6, slideDuration=4)\n",
    "request_count.pprint()\n",
    "\n",
    "####### Exercise End ##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:06\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:06\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:08\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:08\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:08\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:10\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:10\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:12\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:12\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:12\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:14\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:14\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:16\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:16\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:16\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:18\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:18\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:22\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:22\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:24\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:24\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:24\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:26\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:26\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:28\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:28\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:28\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:30\n",
      "-------------------------------------------\n",
      "('lj1027.inktomisearch.com', 2)\n",
      "('lj1153.inktomisearch.com', 2)\n",
      "('user-0c8hdkf.cable.mindspring.com', 5)\n",
      "('lj1216.inktomisearch.com', 1)\n",
      "('200.222.33.33', 1)\n",
      "('ladybug.cns.vt.edu', 5)\n",
      "('h24-70-69-74.ca.shawcable.net', 32)\n",
      "('lj1024.inktomisearch.com', 8)\n",
      "('vlp181.vlp.fi', 1)\n",
      "('osdlab.eic.nctu.edu.tw', 1)\n",
      "('h24-70-56-49.ca.shawcable.net', 7)\n",
      "('lj1052.inktomisearch.com', 1)\n",
      "('fw.kcm.org', 2)\n",
      "('acbf6930.ipt.aol.com', 2)\n",
      "('65-37-13-251.nrp2.roc.ny.frontiernet.net', 5)\n",
      "('ic8234.upco.es', 4)\n",
      "('ipcorp-c8b07af1.terraempresas.com.br', 1)\n",
      "('fw1.millardref.com', 7)\n",
      "('lj1089.inktomisearch.com', 1)\n",
      "('cacher2-ext.wise.edt.ericsson.se', 1)\n",
      "('h24-71-236-129.ca.shawcable.net', 51)\n",
      "('mmscrm07-2.sac.overture.com', 3)\n",
      "('d207-6-50-215.bchsia.telus.net', 1)\n",
      "('212.21.228.26', 1)\n",
      "('cr020r01-3.sac.overture.com', 44)\n",
      "('208-186-146-13.nrp3.brv.mn.frontiernet.net', 2)\n",
      "('pool-68-160-195-60.ny325.east.verizon.net', 5)\n",
      "('lj1123.inktomisearch.com', 2)\n",
      "('145.253.208.9', 7)\n",
      "('prxint-sxb2.e-i.net', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:30\n",
      "-------------------------------------------\n",
      "('lj1027.inktomisearch.com', (2, ''))\n",
      "('lj1153.inktomisearch.com', (2, ''))\n",
      "('ns.wtbts.org', (12, ''))\n",
      "('lj1216.inktomisearch.com', (1, ''))\n",
      "('user-0c8hdkf.cable.mindspring.com', (5, ''))\n",
      "('ladybug.cns.vt.edu', (5, ''))\n",
      "('h24-70-69-74.ca.shawcable.net', (32, ''))\n",
      "('osdlab.eic.nctu.edu.tw', (1, ''))\n",
      "('lj1052.inktomisearch.com', (1, ''))\n",
      "('fw.kcm.org', (2, ''))\n",
      "('cr020r01-3.sac.overture.com', (44, ''))\n",
      "('200.222.33.33', (1, ''))\n",
      "('ic8234.upco.es', (4, ''))\n",
      "('ipcorp-c8b07af1.terraempresas.com.br', (1, ''))\n",
      "('145.253.208.9', (7, ''))\n",
      "('fw1.millardref.com', (7, ''))\n",
      "('lj1089.inktomisearch.com', (1, ''))\n",
      "('cacher2-ext.wise.edt.ericsson.se', (1, ''))\n",
      "('spot.nnacorp.com', (5, ''))\n",
      "('h24-71-236-129.ca.shawcable.net', (51, ''))\n",
      "('h24-70-56-49.ca.shawcable.net', (7, ''))\n",
      "('acbf6930.ipt.aol.com', (2, ''))\n",
      "('212.21.228.26', (1, ''))\n",
      "('mmscrm07-2.sac.overture.com', (3, ''))\n",
      "('pool-68-160-195-60.ny325.east.verizon.net', (5, ''))\n",
      "('lj1123.inktomisearch.com', (2, ''))\n",
      "('prxint-sxb2.e-i.net', (1, ''))\n",
      "('80.58.35.111.proxycache.rima-tde.net', (1, ''))\n",
      "('d97082.upc-d.chello.nl', (1, ''))\n",
      "('d207-6-50-215.bchsia.telus.net', (1, ''))\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:32\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:32\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:32\n",
      "-------------------------------------------\n",
      "1545\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:34\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:34\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:36\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:36\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:36\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:38\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:38\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start() \n",
    "# ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:42\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:42\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:44\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:44\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-01 18:54:44\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.stop(stopSparkContext=True, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://spark.apache.org/docs/latest/streaming-programming-guide.html#window-operations\n",
    "2. https://github.com/jadianes/kdd-cup-99-spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
