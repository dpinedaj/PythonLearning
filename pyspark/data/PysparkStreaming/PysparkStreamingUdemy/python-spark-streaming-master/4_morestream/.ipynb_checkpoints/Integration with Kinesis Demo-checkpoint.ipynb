{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration with Kinesis Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Tuning\n",
    "Reference: https://spark.apache.org/docs/latest/streaming-programming-guide.html#performance-tuning\n",
    "Reducing the Batch Processing Times\n",
    "Level of Parallelism in Data Receiving\n",
    "Level of Parallelism in Data Processing\n",
    "Data Serialization\n",
    "Task Launching Overheads\n",
    "Setting the Right Batch Interval\n",
    "Memory Tuning\n",
    "Integration with Kinesis\n",
    "Introduction to Kinesis\n",
    "Why integrate with Kinesis\n",
    "DEMO: Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kinesis import KinesisUtils, InitialPositionInStream\n",
    "import sys  \n",
    "\n",
    "def foo(line):\n",
    "  print(line)\n",
    "  return line.split(\" \") \n",
    "\n",
    "def printRecord(rdd):\n",
    "    print(\"========================================================\")\n",
    "    print(\"Starting new RDD\")\n",
    "    print(\"========================================================\")\n",
    "    rdd.foreach(lambda record: print(record.encode('utf8')))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    reload(sys)  \n",
    "    sys.setdefaultencoding('utf-8')\n",
    "\n",
    "    if len(sys.argv) != 5:\n",
    "        print( \"Usage: dump.py <app-name> <stream-name> <endpoint-url> <region-name>\", file=sys.stderr)\n",
    "        sys.exit(-1)\n",
    "\n",
    "    sc = SparkContext(appName=\"PythonStreamingKinesisWordCountAsl\")\n",
    "    ssc = StreamingContext(sc, 10)\n",
    "    appName, streamName, endpointUrl, regionName = sys.argv[1:]\n",
    "    dstream = KinesisUtils.createStream(\n",
    "        ssc, appName, streamName, endpointUrl, regionName, InitialPositionInStream.TRIM_HORIZON, 10)\n",
    "    dstream.foreachRDD(printRecord)\n",
    "    ssc.start()\n",
    "    ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://spark.apache.org/docs/latest/streaming-kinesis-integration.html\n",
    "2. https://spark.apache.org/docs/latest/streaming-programming-guide.html#performance-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
