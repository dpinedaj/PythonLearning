{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration with Kinesis Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Tuning\n",
    "Reference: https://spark.apache.org/docs/latest/streaming-programming-guide.html#performance-tuning\n",
    "Reducing the Batch Processing Times\n",
    "Level of Parallelism in Data Receiving\n",
    "Level of Parallelism in Data Processing\n",
    "Data Serialization\n",
    "Task Launching Overheads\n",
    "Setting the Right Batch Interval\n",
    "Memory Tuning\n",
    "Integration with Kinesis\n",
    "Introduction to Kinesis\n",
    "Why integrate with Kinesis\n",
    "DEMO: Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "# TODO: your path will likely not have 'matthew' in it. Change it to reflect your path.\n",
    "findspark.init('/home/matthew/spark-2.1.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kinesis import KinesisUtils, InitialPositionInStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(line):\n",
    "    print(line)\n",
    "    return line.split(\" \") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printRecord(rdd):\n",
    "    print(\"========================================================\")\n",
    "    print(\"Starting new RDD\")\n",
    "    print(\"========================================================\")\n",
    "    rdd.foreach(lambda record: print(record.encode('utf8')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf-8')\n",
    "\n",
    "sc = SparkContext(appName=\"PythonStreamingKinesisWordCountAsl\")\n",
    "ssc = StreamingContext(sc, 10)\n",
    "appName, streamName, endpointUrl, regionName = sys.argv[1:]\n",
    "dstream = KinesisUtils.createStream(ssc, appName, streamName, endpointUrl, regionName, InitialPositionInStream.TRIM_HORIZON, 10)\n",
    "dstream.foreachRDD(printRecord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://spark.apache.org/docs/latest/streaming-kinesis-integration.html\n",
    "2. https://spark.apache.org/docs/latest/streaming-programming-guide.html#performance-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
